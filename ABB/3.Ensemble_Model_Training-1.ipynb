{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac9800e",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9ebe5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6dd352e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "80d76a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/enhanced_train.csv')\n",
    "df_test = pd.read_csv('data/enhanced_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e8c3ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed for training\n",
    "drop_cols = ['Unnamed: 0', 'Item_Outlet_Sales','Log_Sales']\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df['Log_Sales']  # Use log-transformed target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e63b72",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "babca37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Item_Identifiers in train: {'FDN52', 'DRE01', 'NCS41', 'FDE52', 'FDK57'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Create a DataFrame that includes X and stratification column\n",
    "df['Log_Sales'] = y  # just in case\n",
    "df['Freq_Bin_Item_Cluster'] = df['Freq_Bin_Item_Cluster'].astype(str)  # ensure string for stratification\n",
    "\n",
    "# 2. Prepare stratified splitter\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in splitter.split(df, df['Freq_Bin_Item_Cluster']):\n",
    "    df_train_split = df.iloc[train_idx].copy()\n",
    "    df_val_split = df.iloc[val_idx].copy()\n",
    "\n",
    "# 3. Remove rows from val that contain Item_Identifiers not present in train\n",
    "val_unique_items = set(df_val_split['Item_Identifier'])\n",
    "train_unique_items = set(df_train_split['Item_Identifier'])\n",
    "\n",
    "missing_items = val_unique_items - train_unique_items\n",
    "print(f\"Missing Item_Identifiers in train: {missing_items}\")\n",
    "\n",
    "# 4. Move those rows to train\n",
    "rows_to_move = df_val_split[df_val_split['Item_Identifier'].isin(missing_items)]\n",
    "df_train_split = pd.concat([df_train_split, rows_to_move], axis=0)\n",
    "df_val_split = df_val_split[~df_val_split['Item_Identifier'].isin(missing_items)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "45ca5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_split.drop(columns=['Item_Outlet_Sales', 'Log_Sales','Unnamed: 0'])\n",
    "y_train = df_train_split['Log_Sales']\n",
    "\n",
    "X_val = df_val_split.drop(columns=['Item_Outlet_Sales', 'Log_Sales','Unnamed: 0'])\n",
    "y_val = df_val_split['Log_Sales']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "96b211d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sanity check: No missing profiles\n",
    "train_profiles = set(df.loc[X_train.index, 'Item_Profile'])\n",
    "val_profiles = set(df.loc[X_val.index, 'Item_Profile'])\n",
    "missing_profiles = val_profiles - train_profiles\n",
    "if missing_profiles:\n",
    "    print(f\"Warning: Some item profiles are only in validation: {missing_profiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "902ea049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode categoricals\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_val_encoded = pd.get_dummies(X_val)\n",
    "# üîÅ Align columns (same fix applies to all models)\n",
    "X_train_encoded, X_val_encoded = X_train_encoded.align(X_val_encoded, join='left', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "832e7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ridge = ridge = Ridge(\n",
    "    alpha=10.0,             # increase regularization to reduce overfitting\n",
    "    solver='auto',          # works well in most cases\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,        # more trees = more stability\n",
    "    max_depth=15,            # deeper trees (but not too deep)\n",
    "    min_samples_split=10,    # prevent overfitting on small splits\n",
    "    min_samples_leaf=4,      # avoid learning tiny leaves\n",
    "    max_features='sqrt',     # use sqrt(n_features) at each split (faster, robust)\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,          # enough trees to capture complexity\n",
    "    learning_rate=0.01,        # small step to generalize better\n",
    "    max_depth=7,               # reasonable depth, avoids overfitting\n",
    "    subsample=0.8,             # row sampling to reduce variance\n",
    "    colsample_bytree=0.8,      # column sampling to reduce feature noise\n",
    "    min_child_weight=3,        # control splits with small data\n",
    "    gamma=0.1,                 # penalize unnecessary splits\n",
    "    reg_alpha=1.0,             # L1 regularization (sparsity)\n",
    "    reg_lambda=2.0,            # L2 regularization (stability)\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "21064b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10.0, random_state=42)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit base models\n",
    "ridge.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "203716ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=15, max_features='sqrt', min_samples_leaf=4,\n",
       "                      min_samples_split=10, n_estimators=500, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61dcc0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.1, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be5ad6",
   "metadata": {},
   "source": [
    "Prediction on Validation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd289e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_preds = ridge.predict(X_val_encoded)\n",
    "rf_preds = rf.predict(X_val_encoded)\n",
    "xgb_preds = xgb.predict(X_val_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8fe99bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 1100.5463\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "# Inverse log1p\n",
    "y_val_true = np.expm1(y_val)\n",
    "ridge_preds = ridge.predict(X_val_encoded)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_val_true, np.expm1(ridge_preds)))\n",
    "print(f\"Ridge RMSE: {rmse_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1e74f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random Forest RMSE: 1377.7045\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_preds = rf.predict(X_val_encoded)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_val_true, np.expm1(rf_preds)))\n",
    "print(f\" Random Forest RMSE: {rmse_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "df68d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGBoost RMSE: 1116.4576\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_preds = xgb.predict(X_val_encoded)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_val_true, np.expm1(xgb_preds)))\n",
    "print(f\" XGBoost RMSE: {rmse_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9bf577",
   "metadata": {},
   "source": [
    "Average Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c7e10926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation RMSE: 1157.2310\n"
     ]
    }
   ],
   "source": [
    "# Average predictions (in log space)\n",
    "avg_preds_log = (ridge_preds + rf_preds + xgb_preds) / 3\n",
    "avg_preds = np.expm1(avg_preds_log)\n",
    "y_val_actual = np.expm1(y_val)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_val_actual, avg_preds))\n",
    "print(f\"Ensemble Validation RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "42f1c47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Ensemble RMSE: 1107.6767\n"
     ]
    }
   ],
   "source": [
    "# Try weights (e.g., XGB strong, RF medium, Ridge weak)\n",
    "weighted_preds_log = (0.775 * xgb_preds) + (0.0 * rf_preds) + (0.225 * ridge_preds)\n",
    "weighted_preds = np.expm1(weighted_preds_log)\n",
    "\n",
    "rmse_weighted = np.sqrt(mean_squared_error(y_val_actual, weighted_preds))\n",
    "print(f\"Weighted Ensemble RMSE: {rmse_weighted:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2ff9706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble_submission_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Align test features to match train\n",
    "X_test = pd.get_dummies(df_test.drop(columns=['Item_Identifier', 'Outlet_Identifier']))\n",
    "X_test = X_test.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Predict using trained models\n",
    "ridge_test_preds_log = ridge.predict(X_test)\n",
    "rf_test_preds_log = rf.predict(X_test)\n",
    "xgb_test_preds_log = xgb.predict(X_test)\n",
    "\n",
    "# Average predictions (in log space)\n",
    "ensemble_test_preds_log = (ridge_test_preds_log + rf_test_preds_log + xgb_test_preds_log) / 3\n",
    "\n",
    "# Inverse log1p to get final predictions\n",
    "ensemble_test_preds = np.expm1(ensemble_test_preds_log)\n",
    "\n",
    "# Create submission file\n",
    "submission = df_test[['Item_Identifier', 'Outlet_Identifier']].copy()\n",
    "submission['Item_Outlet_Sales'] = ensemble_test_preds\n",
    "\n",
    "#Save to CSV\n",
    "submission.to_csv('ensemble_submission_1.csv', index=False)\n",
    "print(\"Saved ensemble_submission_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cfe6207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best RMSE: 1098.7319\n",
      "üèãÔ∏è‚Äç‚ôÇÔ∏è Optimal Weights ‚Üí XGBoost: 0.225, RF: 0.000, Ridge: 0.775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_weights = (0.0, 0.0, 0.0)\n",
    "\n",
    "weight_range = np.arange(0.0, 1.025, 0.025)\n",
    "\n",
    "for w1 in weight_range:  # XGBoost\n",
    "    for w2 in weight_range:\n",
    "        w3 = 1.0 - w1 - w2\n",
    "        if w3 < 0 or w3 > 1:\n",
    "            continue\n",
    "        ensemble_log_preds = w1 * xgb_preds + w2 * rf_preds + w3 * ridge_preds\n",
    "        rmse = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(ensemble_log_preds)))\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_weights = (w1, w2, w3)\n",
    "\n",
    "print(f\"‚úÖ Best RMSE: {best_rmse:.4f}\")\n",
    "print(f\"üèãÔ∏è‚Äç‚ôÇÔ∏è Optimal Weights ‚Üí XGBoost: {best_weights[0]:.3f}, RF: {best_weights[1]:.3f}, Ridge: {best_weights[2]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
